{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "PyTorch Tensor Examples",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r_ybX-tBEvY"
      },
      "source": [
        "# Some PyTorch Tensor operation examples\n",
        "\n",
        "Firstly, creation of Tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXtKAsUwAvm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "335019b3-04a7-4c91-e530-0d0f06ac9521"
      },
      "source": [
        "import torch\n",
        "# create an empty floating point tensor\n",
        "print(torch.__version__)\n",
        "x = torch.empty(1, 3)\n",
        "print(x)\n",
        "\n",
        "# Creation of default floating point tensor (float32) filled with ones\n",
        "y = torch.ones(2,5)\n",
        "\n",
        "# Creation of Integer tensor from existing data; The bad way (because you've _explicitly_ created a CPU-backed Tensor)\n",
        "zbad = torch.IntTensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(zbad)\n",
        "\n",
        "# Creation of Integer tensor from existing data; The good way (this way allows you to specify device=... so it could be backed by the GPU)\n",
        "z = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float)\n",
        "print(z)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0+cu101\n",
            "tensor([[2.2014e-35, 0.0000e+00, 1.5975e-43]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]], dtype=torch.int32)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNOsZ4DvBAUy"
      },
      "source": [
        "Inspecting a tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZGG-K1TAvm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c601a06d-a5d9-49d8-d39e-871f6c6e3ab9"
      },
      "source": [
        "print(x.size())\n",
        "print(x.shape) #usually used in preference to size()\n",
        "\n",
        "print(z.type()) # the underlying class; this will be dependent on the backing device (so there are different FloatTensor implementations for different devices)\n",
        "print(z.device) # the actual backing device (which isn't just cpu/gpu, but could tell you which gpu...)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3])\n",
            "torch.Size([1, 3])\n",
            "torch.FloatTensor\n",
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM9cD8v-GCsK"
      },
      "source": [
        "Setting values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tJstUUaAvnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c7caa19-2457-4669-9a9b-7747f56bf314"
      },
      "source": [
        "x[0,0] = 0 #setting a specific value\n",
        "print(x)\n",
        "\n",
        "x[0,1:2] = 0 #setting a range of values (the slice operator : works just like in numpy)\n",
        "print(x)\n",
        "\n",
        "# Setting all  the values. Note all in-place operations are suffixed with an underscore\n",
        "x.fill_(1.125)\n",
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0000e+00, 0.0000e+00, 5.3249e-44]])\n",
            "tensor([[0.0000e+00, 0.0000e+00, 5.3249e-44]])\n",
            "tensor([[1.1250, 1.1250, 1.1250]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL7uObp2Gqqx"
      },
      "source": [
        "1st-order statistics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGpUpvcnAvnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ea3af8-40c2-49c3-ed4d-642458409232"
      },
      "source": [
        "print(x.mean())\n",
        "print(x.std())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.1250)\n",
            "tensor(0.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifxQZtMVG64j"
      },
      "source": [
        "Note that the return type of these operations is a 0d Tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC5o5nxOG4V6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1463062-ee69-4c6a-f7ca-1e3e71fc0fac"
      },
      "source": [
        "print(x.sum().shape)\n",
        "x.sum()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.3750)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7RL0Zj7HLhD"
      },
      "source": [
        "To get this back to a Python number:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPlWse_mAvnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f0feba-155d-4da1-ed7c-5da8822dee99"
      },
      "source": [
        "## 0d tensor can be converted back to a Python scalar with item()\n",
        "x.sum().item()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVksTK-MHqtK"
      },
      "source": [
        "You can also go straight to a numpy array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXQqXugOAvnT",
        "outputId": "4c4cfa56-dcef-4aae-eeff-3127052c7c24"
      },
      "source": [
        "z.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6SQfF3lIuHB"
      },
      "source": [
        "Note in both cases above, if the Tensor is not already on the CPU, you have to copy it there first otherwise you'll get an error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KtFLvvUI5I3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7882a5fd-9022-47a7-bae4-011821df1fa4"
      },
      "source": [
        "print(z.cpu().numpy())\n",
        "print(z[0,0].item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]]\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xgCRzGNJzxQ"
      },
      "source": [
        "Element-wise operations are easy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmKXTNZsAvnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d050c98-1005-4d04-b92f-11ce27a6e437"
      },
      "source": [
        "x = torch.tensor([ 10., 20., 30.])\n",
        "y = torch.tensor([ 11., 21., 31.])\n",
        "\n",
        "print(x + y) #Tensor-Tensor addition (element-wise addition)\n",
        "print(x - y) #Tensor-Tensor subtraction (element-wise subtraction)\n",
        "print(x * y) #Hadamard product of two tensors\n",
        "print(x / y) #Hadamard division of two tensors\n",
        "print(x**2) #raising to a power\n",
        "print(torch.sin(x)) #applying sin element-wise\n",
        "print(x == 10) #element-wise boolean tests\n",
        "print(x <= 20) #element-wise boolean tests\n",
        "print((x <= 20) & (x==10)) #element-wise logical `and`"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([21., 41., 61.])\n",
            "tensor([-1., -1., -1.])\n",
            "tensor([110., 420., 930.])\n",
            "tensor([0.9091, 0.9524, 0.9677])\n",
            "tensor([100., 400., 900.])\n",
            "tensor([-0.5440,  0.9129, -0.9880])\n",
            "tensor([ True, False, False])\n",
            "tensor([ True,  True, False])\n",
            "tensor([ True, False, False])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8t2E5piL0Wu"
      },
      "source": [
        "Matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-ES1RckAvnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71eeace4-64f2-4c36-bb21-807f92313240"
      },
      "source": [
        "x = torch.tensor([ 10., 20., 30.]) #x is a 1d tensor\n",
        "m = torch.tensor([[ 0., 0., 1. ],[ 0., 2., 0. ],[ 3., 0., 0. ]]) #m is a 2d tensor\n",
        "\n",
        "try:\n",
        "  print(torch.mm(m,x)) #torch.mm performs matrix-matrix multiplication; this will fail because .mm doesn't support broadcasting and the inputs have differing tensor order\n",
        "except Exception as e:\n",
        "  print(\"Error: \" + str(e))\n",
        "print(torch.matmul(m,x)) #torch.matmul performs matrix-matrix multiplication with broadcasting; it will automatically convert x to a 2d tensor so the multiplication can be performed\n",
        "print(m @ x) #ampersand is convienent short-hand notation for matmul\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: mat2 must be a matrix\n",
            "tensor([30., 40., 30.])\n",
            "tensor([30., 40., 30.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhSwen88NnvG"
      },
      "source": [
        "Unsqueezing tensors - this is something you'll probably see a lot; unsqueezing  adds another dimension:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX5TaPmeAvn2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e288578f-dbc9-4a84-ab9f-1754ac43eaad"
      },
      "source": [
        "x = torch.tensor([ 10., 20., 30.])\n",
        "print(x.shape)\n",
        "x.unsqueeze_(-1) #in-place unsqueeze, adding the new dimension in the last position (so we create a _column_ vector)\n",
        "print(x.shape)\n",
        "\n",
        "print(x.t().shape) #note .t() transposes a tensor\n",
        "\n",
        "print(torch.mm(m,x)) #  the previous .mm that failed because of mismatched sizes will now work"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3])\n",
            "torch.Size([3, 1])\n",
            "torch.Size([1, 3])\n",
            "tensor([[30.],\n",
            "        [40.],\n",
            "        [30.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KLIXGL8NsoH"
      },
      "source": [
        "Sometimes we'll need to reshape tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r-PHr5CAvn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3616f56-e5b6-4873-8298-fcf631a9a2c3"
      },
      "source": [
        "x2 = x.reshape(3) # back to where we started!\n",
        "print(x2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10., 20., 30.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrbtLkJOXndQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
